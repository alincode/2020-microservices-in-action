# Staging 環境 CI/CD

這裡我們使用的是 GCP 的 Cloud Build 服務，因為 staging 環境跟 production 環境要執行的步驟稍微有一些差異，所以我們把 config 分開寫。

### 步驟說明

1. 安裝相依模組
1. 執行整合測試
1. 打包客製化的 image，並採用 kaniko 的快取策略。
1. 將 image 上傳到 GCR 服務
1. 自動部署微服務

### Kaniko 參數說明

- build-arg
- cache
  - 使用 kaniko 進行緩存
  - 範例：true
- cache-dir
  - 要 cache 的資料夾位置
  - 範例：/cache
- cache-ttl
  - 設定多久後 Cache 會過期，預設是兩週。
  - 範例：6h
- destination

  - 你的 image 要上傳的位置
  - 範例：`gcr.io/$PROJECT_ID/auth-server:ci-$_NODE_ENV-$SHORT_SHA`

- [kaniko - Build Images In Kubernetes](https://github.com/GoogleContainerTools/kaniko)

### 完整的 staging-auth-ci.yaml 檔案

```yaml
steps:
  - name: node:12.18.3
    id: yarn-install
    entrypoint: yarn
    args: ["install"]

  - name: node:12.18.3
    id: auth-test
    env:
      - "NEW_RELIC_NO_CONFIG_FILE=true"
      - "NEW_RELIC_ENABLED=false"
    entrypoint: npm
    args: ["run", "test"]
    dir: "packages/auth-server"

  - name: "gcr.io/kaniko-project/executor:v0.22.0"
    id: auth-build
    env: ["NODE_ENV=$_NODE_ENV"]
    args:
      - --dockerfile=docker/auth-server.Dockerfile
      - --build-arg=NODE_ENV=$_NODE_ENV
      - --destination=gcr.io/$PROJECT_ID/auth-server:ci-$_NODE_ENV-$SHORT_SHA
      - --cache=true
      - --cache-ttl=6h

  - name: "gcr.io/cloud-builders/kubectl"
    args:
      - set
      - image
      - deployment
      - auth-deployment
      - auth-server=gcr.io/$PROJECT_ID/auth-server:ci-$_NODE_ENV-$SHORT_SHA
    env:
      - "CLOUDSDK_COMPUTE_ZONE=asia-east1-a"
      - "CLOUDSDK_CONTAINER_CLUSTER=staging-cluster"
```
